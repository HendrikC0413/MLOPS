{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cc028237",
   "metadata": {},
   "source": [
    "\n",
    "# Laboratorio de MLOps -  Ciclo de Vida del Flujo de Trabajo de ML\n",
    "\n",
    "### Objetivo General del Laboratorio\n",
    "Proporcionar experiencia práctica en la aplicación del ciclo de vida del flujo de trabajo de ML, desde la exploración y preprocesamiento de datos hasta la evaluación y mejora de modelos.\n",
    "\n",
    "### Objetivos Específicos\n",
    "1. **Exploración de Datos:** Identificar características y patrones relevantes en los datos.\n",
    "2. **Preprocesamiento de Datos:** Optimizar los datos para el modelado.\n",
    "3. **Modelado de ML:** Aplicar y evaluar un modelo de regresión lineal, comprendiendo los fundamentos del modelado.\n",
    "4. **Comparación de Modelos:** Experimentar con Random Forest para aprender sobre la selección y comparación de modelos.\n",
    "5. **Iteración del Modelo:** Desarrollar habilidades en la mejora continua de los modelos de ML.\n",
    "\n",
    "#### Nota: adjunto GITHUB: https://github.com/HendrikC0413/MLOPS en donde se subiran todos los laboratorios\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e46388f",
   "metadata": {},
   "source": [
    "\n",
    "___\n",
    "## 1. Exploración de Datos\n",
    "Continuando con el laboratorio anterior de IA, el cual se nos solicitó realizar una comparación utilizando los datos del anterior laboratorio de IA ( en mi caso utilice temperatura contra las ventas de helado), pero esta vez utilizaré una libreria que encontre buscando en la documentacion de scikit-learn. Gradient Boost"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15abd9bc",
   "metadata": {},
   "source": [
    "Cargamos las librerias,  el conjunto de datos  de \"icecreamsales- temperatures .csv\" y mostramos las primeras filas para verificar si se cargó correctamente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2746f2b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Temperature  Ice Cream Profits\n",
      "0           39              13.17\n",
      "1           40              11.88\n",
      "2           41              18.82\n",
      "3           42              18.65\n",
      "4           43              17.02\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "data = pd.read_csv('IceCreamSales-temperatures.csv')\n",
    "print(data.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "719fb8e8",
   "metadata": {},
   "source": [
    "## 2. Preprocesamiento de Datos\n",
    "Prepararemos los datos para el modelado, incluyendo la limpieza y la normalización."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8d55939",
   "metadata": {},
   "source": [
    "A diferencia del laboratorio anterior esta vez debemos realizar el procesamiento de los datos, esto para evitar que hayan datos esten muy por encima de los otros valores, ademas de dividir los datos para tener un conjunto de entrenamiento y otro para realizar las pruebas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2e1ef7ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0cd857cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selección de características y variable objetivo\n",
    "X = data.drop('Ice Cream Profits', axis=1) #La independiente\n",
    "y = data['Ice Cream Profits'] #La que quiero predecir\n",
    "\n",
    "# División en conjuntos de entrenamiento y prueba\n",
    "# train_test_split(VAR_Independiente, LA_que_quiero_predecir, test_size= (en % 0.2 = 20% para testeo y el 80% para entrenamiento), random_state=(opcional, que sea reproducible, otro random_state misma division))\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Normalización, para que tengan la misma escala y el modelo no sea influenciado por algunas caracteisticas con escalas muy diferentes\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "330daa3a",
   "metadata": {},
   "source": [
    "## 3. Modelado Básico\n",
    "Entrenaremos un modelo de regresión lineal para predecir los precios de los helados. (normal como en el lab anterior)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "82e842fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LinearRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LinearRegression</label><div class=\"sk-toggleable__content\"><pre>LinearRegression()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "model = LinearRegression()\n",
    "model.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27e88d7c",
   "metadata": {},
   "source": [
    "## 4. Evaluación de Modelos\n",
    "Evaluaremos el rendimiento del modelo utilizando el conjunto de prueba."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f04bcf73",
   "metadata": {},
   "source": [
    "En la evaluación de modelos, usamos el conjunto de prueba para medir la capacidad del modelo de hacer predicciones precisas en datos no vistos, lo que indica su capacidad de generalización. Se emplea el Error Cuadrático Medio (MSE) como métrica porque cuantifica la diferencia entre los valores predichos y los reales, proporcionando una medida clara del rendimiento del modelo en términos de error promedio.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0666e888",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "32baffd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 5.294200791081216\n"
     ]
    }
   ],
   "source": [
    "#Usamos los datos escalados que dejamos para el entrenamiento par que atraves del MSE sepamos cuan bien esta la prediccion\n",
    "y_pred = model.predict(X_test_scaled)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print(f'MSE: {mse}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c3e5fc2",
   "metadata": {},
   "source": [
    "Como podemos observar tenemos un MSE de 5.294 lo cual es bastante bajo, pero como esto dependerá del contexto podemos comparar el linnear regresion con el otro modelo ya nombrado anteriormente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7a61f070",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 5.294200791081216\n",
      "Varianza de la variable objetivo: 255.64824677555322\n",
      "Rango de la variable objetivo: 77.41000000000001\n",
      "Relación MSE/Varianza: 0.02070892665158493\n",
      "Relación MSE/Rango: 0.06839169088078045\n"
     ]
    }
   ],
   "source": [
    "# Calculando la varianza y el rango de la variable objetivo\n",
    "variance = y.var()\n",
    "data_range = y.max() - y.min()\n",
    "\n",
    "print(f'MSE: {mse}')\n",
    "print(f'Varianza de la variable objetivo: {variance}')\n",
    "print(f'Rango de la variable objetivo: {data_range}')\n",
    "\n",
    "# Comparando el MSE con la varianza y el rango\n",
    "print(f'Relación MSE/Varianza: {mse/variance}')\n",
    "print(f'Relación MSE/Rango: {mse/data_range}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9097ecd",
   "metadata": {},
   "source": [
    "Si comparamos el MSE con la Varianza y el rango de mejora podemos observar que existe un amplio margen entre estos valores por lo cual podemos decir que el modelo esta realizando un buen trabajo de predicción acercandonos bastante a los valores reales pero aun asi hay que tener cuidado ya que esto no es una regla sino que dependera del contexto"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da584597",
   "metadata": {},
   "source": [
    "## 5. Iteración del Modelo\n",
    "\n",
    "Ahora probaremos con el Gradient Boosting para ver si existe una mejoría en estos los datos.\n",
    "\n",
    "Gradient Boosting, es un algoritmo de aprendizaje automático que crea un modelo predictivo en forma de un conjunto de modelos de predicción débiles, generalmente árboles de decisión"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9b6492c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import HistGradientBoostingRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1cf7cd67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient Boosting MSE: 9.882517263712282\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Crear y entrenar el modelo de Gradient Boosting (Max_iter , determina el numero maximo de iteraciones(arboles) que se añadiran al modelo)\n",
    "gb_model = HistGradientBoostingRegressor(max_iter=100, random_state=42)\n",
    "gb_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Realizar predicciones con el modelo de Gradient Boosting\n",
    "gb_pred = gb_model.predict(X_test_scaled)\n",
    "\n",
    "# Evaluar el modelo de Gradient Boosting\n",
    "gb_mse = mean_squared_error(y_test, gb_pred)\n",
    "print(f'Gradient Boosting MSE: {gb_mse}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89e8c5ed",
   "metadata": {},
   "source": [
    "El resultado de `9.882` para el MSE del modelo Gradient Boosting, si comparamos al resultado del LinnearReggresion que fue de `5.294`nos dice que en comparacion el gradient boosting es peor y puede que no sea una solucion eficiente o efectiva para este problema y solo necesitamos utilizar el de regresion lineal"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
