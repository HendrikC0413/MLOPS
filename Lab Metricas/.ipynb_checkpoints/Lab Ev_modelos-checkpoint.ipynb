{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9b8fe7bf-3707-4978-a486-a961280436b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importación de librerías necesarias\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score, roc_auc_score, confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "19f047db-511c-4a54-9d3e-72675fc4f303",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#rLeemos el csv\n",
    "data = pd.read_csv(\"AusDataForRainPred.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "454d842c-0a01-45b1-923c-c4ba0b5ea018",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Location</th>\n",
       "      <th>MinTemp</th>\n",
       "      <th>MaxTemp</th>\n",
       "      <th>Rainfall</th>\n",
       "      <th>Evaporation</th>\n",
       "      <th>Sunshine</th>\n",
       "      <th>WindGustDir</th>\n",
       "      <th>WindGustSpeed</th>\n",
       "      <th>WindDir9am</th>\n",
       "      <th>...</th>\n",
       "      <th>Humidity9am</th>\n",
       "      <th>Humidity3pm</th>\n",
       "      <th>Pressure9am</th>\n",
       "      <th>Pressure3pm</th>\n",
       "      <th>Cloud9am</th>\n",
       "      <th>Cloud3pm</th>\n",
       "      <th>Temp9am</th>\n",
       "      <th>Temp3pm</th>\n",
       "      <th>RainToday</th>\n",
       "      <th>RainTomorrow</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2008-12-01</td>\n",
       "      <td>Albury</td>\n",
       "      <td>13.4</td>\n",
       "      <td>22.9</td>\n",
       "      <td>0.6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>W</td>\n",
       "      <td>44.0</td>\n",
       "      <td>W</td>\n",
       "      <td>...</td>\n",
       "      <td>71.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1007.7</td>\n",
       "      <td>1007.1</td>\n",
       "      <td>8.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16.9</td>\n",
       "      <td>21.8</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2008-12-02</td>\n",
       "      <td>Albury</td>\n",
       "      <td>7.4</td>\n",
       "      <td>25.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>WNW</td>\n",
       "      <td>44.0</td>\n",
       "      <td>NNW</td>\n",
       "      <td>...</td>\n",
       "      <td>44.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>1010.6</td>\n",
       "      <td>1007.8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>17.2</td>\n",
       "      <td>24.3</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2008-12-03</td>\n",
       "      <td>Albury</td>\n",
       "      <td>12.9</td>\n",
       "      <td>25.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>WSW</td>\n",
       "      <td>46.0</td>\n",
       "      <td>W</td>\n",
       "      <td>...</td>\n",
       "      <td>38.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>1007.6</td>\n",
       "      <td>1008.7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>23.2</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2008-12-04</td>\n",
       "      <td>Albury</td>\n",
       "      <td>9.2</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NE</td>\n",
       "      <td>24.0</td>\n",
       "      <td>SE</td>\n",
       "      <td>...</td>\n",
       "      <td>45.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>1017.6</td>\n",
       "      <td>1012.8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>18.1</td>\n",
       "      <td>26.5</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2008-12-05</td>\n",
       "      <td>Albury</td>\n",
       "      <td>17.5</td>\n",
       "      <td>32.3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>W</td>\n",
       "      <td>41.0</td>\n",
       "      <td>ENE</td>\n",
       "      <td>...</td>\n",
       "      <td>82.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>1010.8</td>\n",
       "      <td>1006.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>29.7</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date Location  MinTemp  MaxTemp  Rainfall  Evaporation  Sunshine  \\\n",
       "0  2008-12-01   Albury     13.4     22.9       0.6          NaN       NaN   \n",
       "1  2008-12-02   Albury      7.4     25.1       0.0          NaN       NaN   \n",
       "2  2008-12-03   Albury     12.9     25.7       0.0          NaN       NaN   \n",
       "3  2008-12-04   Albury      9.2     28.0       0.0          NaN       NaN   \n",
       "4  2008-12-05   Albury     17.5     32.3       1.0          NaN       NaN   \n",
       "\n",
       "  WindGustDir  WindGustSpeed WindDir9am  ... Humidity9am  Humidity3pm  \\\n",
       "0           W           44.0          W  ...        71.0         22.0   \n",
       "1         WNW           44.0        NNW  ...        44.0         25.0   \n",
       "2         WSW           46.0          W  ...        38.0         30.0   \n",
       "3          NE           24.0         SE  ...        45.0         16.0   \n",
       "4           W           41.0        ENE  ...        82.0         33.0   \n",
       "\n",
       "   Pressure9am  Pressure3pm  Cloud9am  Cloud3pm  Temp9am  Temp3pm  RainToday  \\\n",
       "0       1007.7       1007.1       8.0       NaN     16.9     21.8         No   \n",
       "1       1010.6       1007.8       NaN       NaN     17.2     24.3         No   \n",
       "2       1007.6       1008.7       NaN       2.0     21.0     23.2         No   \n",
       "3       1017.6       1012.8       NaN       NaN     18.1     26.5         No   \n",
       "4       1010.8       1006.0       7.0       8.0     17.8     29.7         No   \n",
       "\n",
       "   RainTomorrow  \n",
       "0            No  \n",
       "1            No  \n",
       "2            No  \n",
       "3            No  \n",
       "4            No  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3574a5bd-375c-4f7e-81ed-74c99c0e55fa",
   "metadata": {},
   "source": [
    "## Preparación de los datos:\n",
    "Vamos a seleccionar un subconjunto específico de columnas y conviertir el DataFrame resultante en un array de NumPy.\n",
    "\n",
    "**iloc[]:** Es un método de pandas que permite la selección por índices de posición (filas y columnas).\n",
    "\n",
    "El **:** antes de la coma significa que seleccionas todas las filas.\n",
    "\n",
    "los **[1,2,3,4,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21]** después de la coma significa que seleccionas las columnas con los índices especificados. En este caso, las columnas con índices 1, 2, 3, 4, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, y 21.\n",
    "\n",
    "El **-1** después de la coma significa que seleccionas la última columna. En pandas, un índice negativo cuenta desde el final hacia el principio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "335cb72d-eddf-45cc-ab26-de5676b1e56d",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = data.iloc[:,[1,2,3,4,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21]].values\n",
    "y = data.iloc[:,-1].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4497d681-c667-41ae-a5b1-45fbebde11e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['Albury' 13.4 22.9 ... 16.9 21.8 'No']\n",
      " ['Albury' 7.4 25.1 ... 17.2 24.3 'No']\n",
      " ['Albury' 12.9 25.7 ... 21.0 23.2 'No']\n",
      " ...\n",
      " ['Uluru' 5.4 26.9 ... 12.5 26.1 'No']\n",
      " ['Uluru' 7.8 27.0 ... 15.1 26.0 'No']\n",
      " ['Uluru' 14.9 nan ... 15.0 20.9 'No']]\n"
     ]
    }
   ],
   "source": [
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7560c2a-6f24-45fc-aca9-5a6dbbabd627",
   "metadata": {},
   "source": [
    "#### Etiquetas para los ejes X e Y\n",
    "**.unique()** es un método de pandas que devuelve los valores únicos de la serie. En este caso, devolverá una lista de los valores únicos presentes en la columna RainTomorrow, que son las clases de nuestro problema de clasificación."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "72471b11-806d-4c2b-b95f-644c66c50a7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = data['RainTomorrow'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b3e4b58-21e9-44d9-bf78-ccc7d38ccd01",
   "metadata": {},
   "source": [
    "### Y como matriz bidimensional\n",
    "El **reshape** es un método de NumPy que permite cambiar la forma de un array sin cambiar sus datos. La forma del array se especifica mediante una tupla de dimensiones.\n",
    "\n",
    "**Descomposición de y.reshape(-1, 1):**\n",
    "y: Es el array original que contiene la variable objetivo.\n",
    ".reshape(): Es el método de NumPy utilizado para cambiar la forma del array.\n",
    "-1: Este valor indica que el tamaño de esta dimensión debe ser inferido a partir del tamaño original del array y el tamaño de la otra dimensión especificada. En este caso, -1 permite que NumPy determine automáticamente el número correcto de filas basado en el tamaño del array original.\n",
    "1: Este valor indica que la nueva forma debe tener exactamente una columna."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "aad4c7f1-3466-4815-8840-8d47000ad744",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['No']\n",
      " ['No']\n",
      " ['No']\n",
      " ...\n",
      " ['No']\n",
      " ['No']\n",
      " [nan]]\n"
     ]
    }
   ],
   "source": [
    "y =  y.reshape(-1,1)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7043616-cbc5-47a3-ba8c-058567a881cb",
   "metadata": {},
   "source": [
    "### Manejo valores faltantes en tus datos (x e y)\n",
    "El **SimpleImputer**  que se utiliza para imputar (sustituir, rellenar) valores faltantes en los datos.\n",
    "\n",
    "Los parámetros utilizados son:\n",
    "\n",
    "**missing_values=np.nan**: Especifica que los valores faltantes en los datos están representados como np.nan (valores NaN de NumPy).\n",
    "\n",
    "**strategy='most_frequent'**: Especifica que la estrategia de imputación será reemplazar los valores faltantes con el valor más frecuente (la moda) de la columna.\n",
    "\n",
    "**fit_transform(x)**: Ajusta el imputador a x y luego transforma x reemplazando los valores faltantes con la moda de cada columna."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dd05b3a5-ee4e-4450-b0f9-cac12e0ee9b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "imputer = SimpleImputer(missing_values = np.nan, strategy='most_frequent')\n",
    "X = imputer.fit_transform(x)\n",
    "Y = imputer.fit_transform(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ffb4f7cf-baa3-4ad6-bce7-4122a83720c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['Albury' 13.4 22.9 ... 16.9 21.8 'No']\n",
      " ['Albury' 7.4 25.1 ... 17.2 24.3 'No']\n",
      " ['Albury' 12.9 25.7 ... 21.0 23.2 'No']\n",
      " ...\n",
      " ['Uluru' 5.4 26.9 ... 12.5 26.1 'No']\n",
      " ['Uluru' 7.8 27.0 ... 15.1 26.0 'No']\n",
      " ['Uluru' 14.9 20.0 ... 15.0 20.9 'No']]\n"
     ]
    }
   ],
   "source": [
    "print(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "aee73dd9-3f10-4a7f-8079-0a55f94b940b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['No']\n",
      " ['No']\n",
      " ['No']\n",
      " ...\n",
      " ['No']\n",
      " ['No']\n",
      " ['No']]\n"
     ]
    }
   ],
   "source": [
    "print(Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8a42f04-0567-45a9-b543-d7feefb6f936",
   "metadata": {},
   "source": [
    "### Transformar variables categóricas en variables numéricas.\n",
    "El **LabelEncoder** asigna un número único a cada categoría en las columnas categóricas y a la variable de destino Y.\n",
    "\n",
    "Se crea objetos LabelEncoder para cada columna categórica y para la variable de destino (Y).\n",
    "\n",
    "y se transforma las variables categóricas en números enteros utilizando cada objeto LabelEncoder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "49f91755-1461-4e59-a3c5-73e013a6b6dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Hendrik\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\preprocessing\\_label.py:114: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "le1 = LabelEncoder()\n",
    "X[:,0] = le1.fit_transform(X[:,0])\n",
    "le2 = LabelEncoder()\n",
    "X[:,4] = le2.fit_transform(X[:,4])\n",
    "le3 = LabelEncoder()\n",
    "X[:,6] = le3.fit_transform(X[:,6])\n",
    "le4 = LabelEncoder()\n",
    "X[:,7] = le4.fit_transform(X[:,7])\n",
    "le5 = LabelEncoder()\n",
    "X[:,-1] = le5.fit_transform(X[:,-1])\n",
    "le6 = LabelEncoder()\n",
    "Y = le6.fit_transform(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9a669924-df49-4504-a3d6-7d6ae88d7b0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2 13.4 22.9 ... 16.9 21.8 0]\n",
      " [2 7.4 25.1 ... 17.2 24.3 0]\n",
      " [2 12.9 25.7 ... 21.0 23.2 0]\n",
      " ...\n",
      " [41 5.4 26.9 ... 12.5 26.1 0]\n",
      " [41 7.8 27.0 ... 15.1 26.0 0]\n",
      " [41 14.9 20.0 ... 15.0 20.9 0]]\n"
     ]
    }
   ],
   "source": [
    "print(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "009cba08-b901-48cf-84bd-bffdbd9be1c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0]\n",
      " [0]\n",
      " [0]\n",
      " ...\n",
      " [0]\n",
      " [0]\n",
      " [0]]\n"
     ]
    }
   ],
   "source": [
    "Y = Y.reshape(-1,1)\n",
    "print(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d0491a19-29b3-40e0-ad59-3e2081748d14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.]\n",
      " [0.]\n",
      " [0.]\n",
      " ...\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]]\n"
     ]
    }
   ],
   "source": [
    "Y = np.array(Y,dtype=float)\n",
    "print(Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2db97caf-23e5-4482-b7fe-47e1eec24ba9",
   "metadata": {},
   "source": [
    "### Normalización de los datos:\n",
    "\n",
    "**StandardScaler**: Es una técnica común para escalar características (variables) de manera que tengan una media de 0 y una desviación estándar de 1. Esto es útil para algoritmos que asumen que las características están centradas alrededor de cero y tienen la misma escala.\n",
    "\n",
    "**sc.fit_transform(X):** fit_transform primero ajusta (calcula la media y la desviación estándar) a los datos de entrada X y luego transforma X utilizando estas estadísticas para centrar los datos alrededor de cero y escalarlos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "24b3e767-91ee-492a-b78e-32555e8da03e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "X = sc.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "00c45063-6399-4565-9cef-cc0f3747d14f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dividir los datos en entrenamiento y prueba\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "945df17a-5c55-4177-ae8d-0bf56088b3c2",
   "metadata": {},
   "source": [
    "## Métricas de Evaluación de Modelos\n",
    "\n",
    "Las métricas de evaluación como precisión, recall, y F1-score son esenciales para entender diferentes aspectos del rendimiento del modelo. Aquí demostramos cómo calcular estas métricas.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "67f0065f-0b26-448d-9236-aee29dcc39f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Hendrik\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\base.py:1474: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.85\n",
      "Recall: 0.49\n",
      "Precision: 0.76\n",
      "F1 Score: 0.59\n",
      "ROC AUC Score: 0.72\n"
     ]
    }
   ],
   "source": [
    "model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Calcular métricas\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "roc_auc = roc_auc_score(y_test, y_pred)\n",
    "\n",
    "print(f\"Accuracy: {accuracy:.2f}\")\n",
    "print(f\"Recall: {recall:.2f}\")\n",
    "print(f\"Precision: {precision:.2f}\")\n",
    "print(f\"F1 Score: {f1:.2f}\")\n",
    "print(f\"ROC AUC Score: {roc_auc:.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f113efba-9160-4412-b82b-15b51d353074",
   "metadata": {},
   "source": [
    "Estas métricas indican un alto desempeño del modelo en el conjunto de prueba, reflejando su capacidad para predecir correctamente tanto las clases positivas como las negativas.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6d89c27-37e2-4b94-9706-5b7fc07112fd",
   "metadata": {},
   "source": [
    "### Explicación de las Métricas de Evaluación y sus Resultados\n",
    "\n",
    "En el contexto de la validación y evaluación de modelos de machine learning, es fundamental entender qué mide cada métrica y cómo interpretar los resultados obtenidos. A continuación, se presentan las definiciones y el análisis de las métricas de evaluación: Accuracy, Recall, Precision, F1 Score y ROC AUC Score, junto con sus resultados específicos.\n",
    "\n",
    "#### Accuracy (Precisión)\n",
    "**Definición:**\n",
    "La precisión es la proporción de predicciones correctas realizadas por el modelo sobre el total de predicciones. Es una métrica global que indica qué tan bien está funcionando el modelo en general.\n",
    "\n",
    "$$\n",
    "\\text{Accuracy} = \\frac{\\text{TP + TN}}{\\text{TP + TN + FP + FN}}\n",
    "$$\n",
    "\n",
    "Donde:\n",
    "- TP: Verdaderos Positivos\n",
    "- TN: Verdaderos Negativos\n",
    "- FP: Falsos Positivos\n",
    "- FN: Falsos Negativos\n",
    "\n",
    "**Resultado: 0.85**\n",
    "- **Interpretación:** La exactitud es del 85%, lo que indica que el 85% de las predicciones son correctas en general. Es una buena medida, pero no nos dice la historia completa, especialmente si hay un desequilibrio entre las clases.\n",
    "\n",
    "#### Recall (Sensibilidad o Tasa de Verdaderos Positivos)\n",
    "**Definición:**\n",
    "El recall mide la capacidad del modelo para identificar todas las instancias positivas. Es especialmente importante en contextos donde no detectar una instancia positiva tiene un alto costo.\n",
    "\n",
    "$$\n",
    "\\text{Recall} = \\frac{\\text{TP}}{\\text{TP + FN}}\n",
    "$$\n",
    "\n",
    "**Resultado: 0.49**\n",
    "- **Interpretación:** El recall es del 49%, lo que significa que el modelo identifica correctamente el 49% de todos los casos positivos. Un valor bajo de recall indica que el modelo podría estar perdiendo muchos casos positivos.\n",
    "\n",
    "#### Precision (Precisión o Valor Predictivo Positivo)\n",
    "**Definición:**\n",
    "La precisión mide la exactitud de las predicciones positivas del modelo. Indica la proporción de verdaderos positivos sobre todas las predicciones positivas.\n",
    "\n",
    "$$\n",
    "\\text{Precision} = \\frac{\\text{TP}}{\\text{TP + FP}}\n",
    "$$\n",
    "\n",
    "**Resultado: 0.76**\n",
    "- **Interpretación:** La precisión es del 76%, lo que significa que del total de casos que el modelo predice como positivos, el 76% realmente son positivos. Una precisión del 76% es decente, pero podría ser mejor.\n",
    "\n",
    "#### F1 Score\n",
    "**Definición:**\n",
    "El F1 Score es la media armónica de la precisión y el recall. Proporciona una única métrica que equilibra la precisión y el recall, especialmente útil cuando se necesita un balance entre ambas.\n",
    "\n",
    "$$\n",
    "\\text{F1 Score} = 2 \\cdot \\frac{\\text{Precision} \\cdot \\text{Recall}}{\\text{Precision + Recall}}\n",
    "$$\n",
    "\n",
    "**Resultado: 0.59**\n",
    "- **Interpretación:** El F1 Score es del 59%. Al combinar precision y recall, nos da una idea del equilibrio entre ambas métricas. Un valor del 59% sugiere un equilibrio moderado entre precision y recall.\n",
    "\n",
    "#### ROC AUC Score (Área bajo la curva ROC)\n",
    "**Definición:**\n",
    "El ROC AUC Score mide la capacidad del modelo para distinguir entre clases. La curva ROC traza la tasa de verdaderos positivos frente a la tasa de falsos positivos en varios umbrales de clasificación.\n",
    "\n",
    "$$\n",
    "\\text{AUC} = \\int_{\\text{ROC}} \\text{d(ROC)}\n",
    "$$\n",
    "\n",
    "**Resultado: 0.72**\n",
    "- **Interpretación:** El ROC AUC Score es del 72%. Indica que el modelo tiene una capacidad razonable para distinguir entre las clases positiva y negativa. Un valor del 72% sugiere un rendimiento decente pero puede haber margen de mejora.\n",
    "\n",
    "### Conclusión\n",
    "Se puede decir que el modelo tiene una exactitud bastante alta, pero podría estar perdiendo algunos casos positivos (bajo recall), además de eso la precisión es decente, pero podría mejorarse para reducir falsos positivos, por otro lado el equilibrio entre precisión y recall (F1 Score) es moderado y el modelo tiene una capacidad razonable para distinguir entre clases según el área bajo la curva ROC. Abria que investigar mas si la ing. de caracteristicas en que sectores se puede mejorar y que sucederia si se aplican diferentes algoritmos. Y por ultimo decir que esto mas o menos se pudo observar cuando vimos la matriz de confusión en notebook anterior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c6df62f-6ad1-43b4-a63e-5c4d86a54f94",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
